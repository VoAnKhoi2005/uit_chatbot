{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-24T05:24:46.004190Z",
     "start_time": "2025-10-24T05:24:44.325255Z"
    }
   },
   "source": [
    "from graph.src.triplet_extraction import init_gpt, init_vncorenlp\n",
    "from graph.src.db import init_sqlite, init_neo4j, delete_all\n",
    "\n",
    "process_conn, process_cursor = init_sqlite(r\"E:\\Github\\uit_chatbot\\graph\\process_law.db\")\n",
    "law_conn, law_cursor = init_sqlite(r\"E:\\Github\\uit_chatbot\\graph\\GTVT_law.db\")\n",
    "gpt_client = init_gpt()\n",
    "neo4j_session = init_neo4j(\n",
    "        uri=\"neo4j://127.0.0.1:7687\",\n",
    "        username=\"neo4j\",\n",
    "        password=\"1234567890\",\n",
    "        db_name=\"neo4j\",\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T05:24:58.198158Z",
     "start_time": "2025-10-24T05:24:46.153276Z"
    }
   },
   "cell_type": "code",
   "source": "vncorenlp_client = init_vncorenlp(r\"E:\\Github\\uit_chatbot\\graph\\VnCoreNLP-1.2\")",
   "id": "28dc35c98bff0e20",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T05:25:14.682619Z",
     "start_time": "2025-10-24T05:24:58.210613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import phonlp\n",
    "phoNLP_model = phonlp.load(save_dir=r\"E:\\Github\\uit_chatbot\\graph\\phonlp\")"
   ],
   "id": "bfcae9535ee0620d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: E:\\Github\\uit_chatbot\\graph\\phonlp/phonlp.pt\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:05:35.057400Z",
     "start_time": "2025-10-24T08:05:35.049607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parsing_result(annotation):\n",
    "    import pandas as pd\n",
    "    words = annotation[0][0]\n",
    "    pos_tags_nested = annotation[1][0]\n",
    "    ner_tags = annotation[2][0]\n",
    "    dep_tags_nested = annotation[3][0]\n",
    "    # Create the 'id' list\n",
    "    ids = list(range(1, len(words) + 1))\n",
    "\n",
    "    # Flatten the POS tags\n",
    "    pos_tags = [tag[0] for tag in pos_tags_nested]\n",
    "\n",
    "    # Split the dependency tags\n",
    "    heads = [dep[0] for dep in dep_tags_nested]\n",
    "    deprels = [dep[1] for dep in dep_tags_nested]\n",
    "\n",
    "    data = {\n",
    "        'id': ids,\n",
    "        'word': words,\n",
    "        'pos': pos_tags,\n",
    "        # 'ner': ner_tags,\n",
    "        'head': heads,\n",
    "        'deprel': deprels\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)"
   ],
   "id": "e136517b201ed012",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T15:32:35.669949Z",
     "start_time": "2025-10-18T15:32:35.665815Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89cdd5f3440d0fd24279d51d996983123336cb3022163dd5fe9866f153ccfd05\n",
      "16/2022/TT-BGTVT Điều 9 Khoản 7 Điểm b \n",
      "đối với thẩm định tài liệu hướng dẫn, hồ sơ bao gồm: 01 bản sao điện tử có giá trị pháp lý (đối với trường hợp nộp thông qua hệ thống dịch vụ công trực tuyến) hoặc 03 bản chính (đối với trường hợp nộp trực tiếp hoặc qua hệ thống bưu chính hoặc hình thức phù hợp khác) tài liệu hướng dẫn.”\n"
     ]
    }
   ],
   "execution_count": 57,
   "source": [
    "from graph.src.triplet_extraction import clean_text\n",
    "from graph.src.db import extract_from_sqlite\n",
    "\n",
    "rows = extract_from_sqlite(law_cursor, \"89cdd5f3440d0fd24279d51d996983123336cb3022163dd5fe9866f153ccfd05\", True)\n",
    "sentence = \"\"\n",
    "title = \"\"\n",
    "for r in rows:\n",
    "    title += r['title'] + \" \"\n",
    "    if not (r['title'].strip().startswith(\"Chương\") or r['title'].strip().startswith(\"Điều\")):\n",
    "        sentence += r['content'] + \"\\n\"\n",
    "\n",
    "so_hieu = r['so_hieu']\n",
    "ID = r['id']\n",
    "print(ID)\n",
    "print(so_hieu + \" \" + title)\n",
    "print(clean_text(sentence))"
   ],
   "id": "254cef1646c60410"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T07:25:33.419287Z",
     "start_time": "2025-10-24T07:25:33.415002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from graph.src.db import extract_random_from_sqlite\n",
    "\n",
    "rows = extract_random_from_sqlite(process_cursor)\n",
    "sentence = rows['content']\n",
    "so_hieu = rows['so_hieu']\n",
    "document_id = rows['id']\n",
    "\n",
    "print(document_id)\n",
    "print(so_hieu)\n",
    "print(sentence)\n",
    "print()"
   ],
   "id": "25a1266bfbe8630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764ee4312a8206628f62ba0285eeb51880713853f374dd40e65b3e82aacc2a08\n",
      "36/2024/QH15\n",
      "Nhiệm vụ của cảnh sát giao thông khi thực hiện tuần tra, kiểm soát bao gồm bảo đảm an ninh, trật tự theo quy định của pháp luật\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from graph.src.triplet_extraction import process_sentence\n",
    "\n",
    "result = process_sentence(sentence, vncorenlp_client, True)"
   ],
   "id": "e1da90c841917361",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T07:25:45.702942Z",
     "start_time": "2025-10-24T07:25:45.589114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = sentence\n",
    "segmented_text = vncorenlp_client.word_segment(text)\n",
    "annotation = phoNLP_model.annotate(text=segmented_text[0])\n",
    "df = parsing_result(annotation)\n",
    "df.style.hide(axis=\"index\")"
   ],
   "id": "87dd719babddea9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a4744de490>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6634c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6634c_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_6634c_level0_col1\" class=\"col_heading level0 col1\" >word</th>\n",
       "      <th id=\"T_6634c_level0_col2\" class=\"col_heading level0 col2\" >pos</th>\n",
       "      <th id=\"T_6634c_level0_col3\" class=\"col_heading level0 col3\" >head</th>\n",
       "      <th id=\"T_6634c_level0_col4\" class=\"col_heading level0 col4\" >deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_6634c_row0_col1\" class=\"data row0 col1\" >Nhiệm_vụ</td>\n",
       "      <td id=\"T_6634c_row0_col2\" class=\"data row0 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row0_col3\" class=\"data row0 col3\" >10</td>\n",
       "      <td id=\"T_6634c_row0_col4\" class=\"data row0 col4\" >sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_6634c_row1_col1\" class=\"data row1 col1\" >của</td>\n",
       "      <td id=\"T_6634c_row1_col2\" class=\"data row1 col2\" >E</td>\n",
       "      <td id=\"T_6634c_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_6634c_row1_col4\" class=\"data row1 col4\" >nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_6634c_row2_col1\" class=\"data row2 col1\" >cảnh_sát</td>\n",
       "      <td id=\"T_6634c_row2_col2\" class=\"data row2 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row2_col3\" class=\"data row2 col3\" >2</td>\n",
       "      <td id=\"T_6634c_row2_col4\" class=\"data row2 col4\" >pob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_6634c_row3_col1\" class=\"data row3 col1\" >giao_thông</td>\n",
       "      <td id=\"T_6634c_row3_col2\" class=\"data row3 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row3_col3\" class=\"data row3 col3\" >3</td>\n",
       "      <td id=\"T_6634c_row3_col4\" class=\"data row3 col4\" >nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_6634c_row4_col1\" class=\"data row4 col1\" >khi</td>\n",
       "      <td id=\"T_6634c_row4_col2\" class=\"data row4 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_6634c_row4_col4\" class=\"data row4 col4\" >tmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_6634c_row5_col1\" class=\"data row5 col1\" >thực_hiện</td>\n",
       "      <td id=\"T_6634c_row5_col2\" class=\"data row5 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row5_col3\" class=\"data row5 col3\" >5</td>\n",
       "      <td id=\"T_6634c_row5_col4\" class=\"data row5 col4\" >nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_6634c_row6_col1\" class=\"data row6 col1\" >tuần_tra</td>\n",
       "      <td id=\"T_6634c_row6_col2\" class=\"data row6 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row6_col3\" class=\"data row6 col3\" >6</td>\n",
       "      <td id=\"T_6634c_row6_col4\" class=\"data row6 col4\" >vmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_6634c_row7_col1\" class=\"data row7 col1\" >,</td>\n",
       "      <td id=\"T_6634c_row7_col2\" class=\"data row7 col2\" >CH</td>\n",
       "      <td id=\"T_6634c_row7_col3\" class=\"data row7 col3\" >7</td>\n",
       "      <td id=\"T_6634c_row7_col4\" class=\"data row7 col4\" >punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_6634c_row8_col1\" class=\"data row8 col1\" >kiểm_soát</td>\n",
       "      <td id=\"T_6634c_row8_col2\" class=\"data row8 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row8_col3\" class=\"data row8 col3\" >7</td>\n",
       "      <td id=\"T_6634c_row8_col4\" class=\"data row8 col4\" >vmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_6634c_row9_col1\" class=\"data row9 col1\" >bao_gồm</td>\n",
       "      <td id=\"T_6634c_row9_col2\" class=\"data row9 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_6634c_row9_col4\" class=\"data row9 col4\" >root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_6634c_row10_col1\" class=\"data row10 col1\" >bảo_đảm</td>\n",
       "      <td id=\"T_6634c_row10_col2\" class=\"data row10 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row10_col3\" class=\"data row10 col3\" >10</td>\n",
       "      <td id=\"T_6634c_row10_col4\" class=\"data row10 col4\" >vmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_6634c_row11_col1\" class=\"data row11 col1\" >an_ninh</td>\n",
       "      <td id=\"T_6634c_row11_col2\" class=\"data row11 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row11_col3\" class=\"data row11 col3\" >11</td>\n",
       "      <td id=\"T_6634c_row11_col4\" class=\"data row11 col4\" >dob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_6634c_row12_col1\" class=\"data row12 col1\" >,</td>\n",
       "      <td id=\"T_6634c_row12_col2\" class=\"data row12 col2\" >CH</td>\n",
       "      <td id=\"T_6634c_row12_col3\" class=\"data row12 col3\" >12</td>\n",
       "      <td id=\"T_6634c_row12_col4\" class=\"data row12 col4\" >punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_6634c_row13_col1\" class=\"data row13 col1\" >trật_tự</td>\n",
       "      <td id=\"T_6634c_row13_col2\" class=\"data row13 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row13_col3\" class=\"data row13 col3\" >12</td>\n",
       "      <td id=\"T_6634c_row13_col4\" class=\"data row13 col4\" >nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_6634c_row14_col1\" class=\"data row14 col1\" >theo</td>\n",
       "      <td id=\"T_6634c_row14_col2\" class=\"data row14 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row14_col3\" class=\"data row14 col3\" >12</td>\n",
       "      <td id=\"T_6634c_row14_col4\" class=\"data row14 col4\" >mnr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row15_col0\" class=\"data row15 col0\" >16</td>\n",
       "      <td id=\"T_6634c_row15_col1\" class=\"data row15 col1\" >quy_định</td>\n",
       "      <td id=\"T_6634c_row15_col2\" class=\"data row15 col2\" >V</td>\n",
       "      <td id=\"T_6634c_row15_col3\" class=\"data row15 col3\" >15</td>\n",
       "      <td id=\"T_6634c_row15_col4\" class=\"data row15 col4\" >vmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row16_col0\" class=\"data row16 col0\" >17</td>\n",
       "      <td id=\"T_6634c_row16_col1\" class=\"data row16 col1\" >của</td>\n",
       "      <td id=\"T_6634c_row16_col2\" class=\"data row16 col2\" >E</td>\n",
       "      <td id=\"T_6634c_row16_col3\" class=\"data row16 col3\" >16</td>\n",
       "      <td id=\"T_6634c_row16_col4\" class=\"data row16 col4\" >vmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6634c_row17_col0\" class=\"data row17 col0\" >18</td>\n",
       "      <td id=\"T_6634c_row17_col1\" class=\"data row17 col1\" >pháp_luật</td>\n",
       "      <td id=\"T_6634c_row17_col2\" class=\"data row17 col2\" >N</td>\n",
       "      <td id=\"T_6634c_row17_col3\" class=\"data row17 col3\" >17</td>\n",
       "      <td id=\"T_6634c_row17_col4\" class=\"data row17 col4\" >pob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:06:49.070632Z",
     "start_time": "2025-10-24T08:06:48.970100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Chủ đầu tư có trách nhiệm bảo trì đoạn đường vừa thi công, vừa khai thác sử dụng trong thời gian bảo hành công trình\"\n",
    "segmented_text = vncorenlp_client.word_segment(text)\n",
    "annotation = phoNLP_model.annotate(text=segmented_text[0])\n",
    "df = parsing_result(annotation)\n",
    "print(df.to_string(index=False))"
   ],
   "id": "7f8870bbf0d2e4a9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id        word pos head deprel\n",
      "  1         Chủ   N    3    sub\n",
      "  2      đầu_tư   V    1   nmod\n",
      "  3          có   V    0   root\n",
      "  4 trách_nhiệm   N    3    dob\n",
      "  5     bảo_trì   V    4   nmod\n",
      "  6        đoạn  Nc    5    dob\n",
      "  7       đường   N    6   nmod\n",
      "  8         vừa   R    9    adv\n",
      "  9    thi_công   V    6   nmod\n",
      " 10           ,  CH    9  punct\n",
      " 11         vừa   R   12    adv\n",
      " 12   khai_thác   V    6   nmod\n",
      " 13     sử_dụng   V   12   vmod\n",
      " 14       trong   E   12    tmp\n",
      " 15   thời_gian   N   14    pob\n",
      " 16    bảo_hành   V   15   nmod\n",
      " 17  công_trình   N   16   vmod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def triplet_extraction(df):\n",
    "    data_dict = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    root_id = None\n",
    "\n",
    "    part1 = []\n",
    "    part2 = []\n",
    "\n",
    "    for token_id, info in data_dict.items():\n",
    "        if not root_id:\n",
    "            part1.append(token_id)\n",
    "        else:\n",
    "            part2.append(token_id)\n",
    "\n",
    "        if info['deprel'] == \"root\" and info['pos'].startswith(\"V\"):\n",
    "            root_id = token_id\n",
    "            break\n",
    "\n",
    "    if root_id:\n",
    "        print(\"No root found\")\n",
    "        return\n",
    "\n",
    "    #Handle part 1\n",
    "    sub_id = next((i for i in part1 if data_dict[i]['deprel'] == 'sub'), None)\n",
    "    if sub_id:\n",
    "        print(\"No sub found\")\n",
    "        return\n",
    "\n"
   ],
   "id": "856ebb113a5cdc47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T05:37:38.996745Z",
     "start_time": "2025-10-24T05:37:38.992324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Save all dependency relation tags to a file\n",
    "output_path = r\"E:\\Github\\uit_chatbot\\graph\\deprel_tags.txt\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for tag in all_deprel_tag:\n",
    "        f.write(tag + \"\\n\")\n",
    "\n",
    "full_path = os.path.abspath(output_path)\n",
    "print(f\"Saved {len(all_deprel_tag)} tags to {full_path}\")\n"
   ],
   "id": "e5a287605501aa33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 24 tags to E:\\Github\\uit_chatbot\\graph\\deprel_tags.txt\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:40:18.465658Z",
     "start_time": "2025-10-24T09:40:18.313503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sentence(df, verbose: bool = True) -> dict:\n",
    "    data_dict = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    # Triplet extraction\n",
    "    triplets = []\n",
    "    concept1_tokens = []\n",
    "    concept2_tokens = []\n",
    "    relation_tokens = []\n",
    "\n",
    "    verb_deprel_tag = ['root', 'vmod', 'nmod', 'x', 'conj', 'prd', 'tpc', 'dep']\n",
    "    remove_POS_tag = [\"R\", \"CH\"]\n",
    "\n",
    "    for token_id, info in data_dict.items():\n",
    "        if any(info['pos'].startswith(prefix) for prefix in remove_POS_tag):\n",
    "            continue\n",
    "\n",
    "        if (token_id - 1) > 0 and (token_id + 1) <= len(df):\n",
    "            between_n = (data_dict[token_id - 1]['pos'].startswith(\"N\") and data_dict[token_id + 1]['pos'].startswith(\"N\"))\n",
    "        else:\n",
    "            between_n = False\n",
    "        token = info['word']\n",
    "\n",
    "        if (info['pos'].startswith(\"V\") and (info['deprel'] in verb_deprel_tag)\n",
    "                and (info['deprel'] != \"nmod\" or not between_n) and info['deprel'] != \"vmod\"):\n",
    "            if concept2_tokens:\n",
    "                triplet = (\n",
    "                    \" \".join(concept1_tokens),\n",
    "                    \" \".join(relation_tokens),\n",
    "                    \" \".join(concept2_tokens)\n",
    "                )\n",
    "                if triplet not in triplets:  # chỉ thêm nếu chưa tồn tại\n",
    "                    triplets.append(triplet)\n",
    "\n",
    "                concept1_tokens = concept2_tokens\n",
    "                concept2_tokens = []\n",
    "                relation_tokens = []\n",
    "            relation_tokens.append(token)\n",
    "        else:\n",
    "            if relation_tokens:\n",
    "                concept2_tokens.append(token)\n",
    "            else:\n",
    "                concept1_tokens.append(token)\n",
    "\n",
    "    if concept1_tokens and relation_tokens and concept2_tokens:\n",
    "        triplets.append((\n",
    "            \" \".join(concept1_tokens),\n",
    "            \" \".join(relation_tokens),\n",
    "            \" \".join(concept2_tokens)\n",
    "        ))\n",
    "\n",
    "    return triplets\n",
    "\n",
    "rows = extract_random_from_sqlite(process_cursor)\n",
    "rand_sentence = rows['content']\n",
    "# rand_sentence = \"\"\n",
    "print(rand_sentence)\n",
    "segmented_text = vncorenlp_client.word_segment(rand_sentence)\n",
    "annotation = phoNLP_model.annotate(text=segmented_text[0])\n",
    "df = parsing_result(annotation)\n",
    "print(df.to_string(index=False))\n",
    "result = process_sentence(df)\n",
    "for triplet in result:\n",
    "    print(triplet)"
   ],
   "id": "f867ad791804462a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi phí vận hành khai thác công trình đường bộ được xác định theo quy định của pháp luật có liên quan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id       word pos head deprel\n",
      "  1    Chi_phí   N    6    sub\n",
      "  2   vận_hành   V    1   nmod\n",
      "  3  khai_thác   V    2   vmod\n",
      "  4 công_trình   N    2   vmod\n",
      "  5   đường_bộ   N    4   nmod\n",
      "  6       được   V    0   root\n",
      "  7   xác_định   V    6   vmod\n",
      "  8       theo   E    7    mnr\n",
      "  9   quy_định   V    8   vmod\n",
      " 10        của   E    9   nmod\n",
      " 11  pháp_luật   N   10    pob\n",
      " 12         có   V   11   nmod\n",
      " 13  liên_quan   V   12   vmod\n",
      "('Chi_phí', 'vận_hành', 'khai_thác công_trình đường_bộ')\n",
      "('khai_thác công_trình đường_bộ', 'được', 'xác_định theo quy_định của pháp_luật')\n",
      "('xác_định theo quy_định của pháp_luật', 'có', 'liên_quan')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:53:57.062316Z",
     "start_time": "2025-10-24T09:53:56.959979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_sentence(df, verbose: bool = True) -> dict:\n",
    "    data_dict = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    # === 1. Tiền xử lý: Tìm chủ ngữ (sub) của tất cả các động từ ===\n",
    "    # Tạo một bản đồ: {verb_id: [subject_id_1, subject_id_2, ...]}\n",
    "    subjects_of_verbs = {}\n",
    "    for token_id, info in data_dict.items():\n",
    "        if info['deprel'] == 'sub':\n",
    "            head_id = info['head'] # ID của động từ\n",
    "            if head_id not in subjects_of_verbs:\n",
    "                subjects_of_verbs[head_id] = []\n",
    "            subjects_of_verbs[head_id].append(token_id) # ID của chủ ngữ\n",
    "\n",
    "    # === 2. Trích xuất Triplet ===\n",
    "    triplets = []\n",
    "    # Thay đổi: Lưu trữ ID thay vì từ (word)\n",
    "    concept1_ids = []\n",
    "    concept2_ids = []\n",
    "    relation_ids = []\n",
    "\n",
    "    verb_deprel_tag = ['root', 'vmod', 'nmod', 'x', 'conj', 'prd', 'tpc', 'dep']\n",
    "    # Thêm 'E' (Giới từ) vào danh sách loại bỏ vì chúng thường là nhiễu\n",
    "    remove_POS_tag = [\"R\", \"CH\", \"E\"]\n",
    "\n",
    "    # Hàm trợ giúp để chuyển danh sách ID thành chuỗi\n",
    "    def ids_to_string(id_list):\n",
    "        id_list.sort() # Sắp xếp các ID để đảm bảo thứ tự từ là đúng\n",
    "        return \" \".join(data_dict[tid]['word'] for tid in id_list)\n",
    "\n",
    "    for token_id, info in data_dict.items():\n",
    "        if any(info['pos'].startswith(prefix) for prefix in remove_POS_tag):\n",
    "            continue\n",
    "\n",
    "        if (token_id - 1) > 0 and (token_id + 1) <= len(df):\n",
    "            between_n = (data_dict[token_id - 1]['pos'].startswith(\"N\") and data_dict[token_id + 1]['pos'].startswith(\"N\"))\n",
    "        else:\n",
    "            between_n = False\n",
    "        token = info['word']\n",
    "\n",
    "        # --- Quyết định token này là Relation hay Concept ---\n",
    "        is_relation = False\n",
    "        if (info['pos'].startswith(\"V\") and (info['deprel'] in verb_deprel_tag)\n",
    "                and (info['deprel'] != \"nmod\" or not between_n) and info['deprel'] != \"vmod\"):\n",
    "\n",
    "            # Mặc định coi nó là relation\n",
    "            is_relation = True\n",
    "\n",
    "            # === 3. LOGIC MỚI: KIỂM TRA ĐỘNG TỪ ROOT ===\n",
    "            if info['deprel'] == 'root':\n",
    "                # Lấy danh sách ID chủ ngữ của động từ 'root' này\n",
    "                subject_ids_for_this_root = subjects_of_verbs.get(token_id, [])\n",
    "\n",
    "                if not subject_ids_for_this_root:\n",
    "                    # Động từ 'root' này không có 'sub' (ví dụ: câu mệnh lệnh)\n",
    "                    # -> Không coi nó là relation, mà là một phần của concept\n",
    "                    is_relation = False\n",
    "                else:\n",
    "                    # Kiểm tra xem concept1 có chứa bất kỳ ID chủ ngữ nào không\n",
    "                    found_subject_in_concept1 = False\n",
    "                    for sub_id in subject_ids_for_this_root:\n",
    "                        if sub_id in concept1_ids:\n",
    "                            found_subject_in_concept1 = True\n",
    "                            break\n",
    "\n",
    "                    if not found_subject_in_concept1:\n",
    "                        # Chủ ngữ không nằm trong concept1.\n",
    "                        # -> Không coi nó là relation, mà là một phần của concept\n",
    "                        is_relation = False\n",
    "            # === Kết thúc logic mới ===\n",
    "\n",
    "        # --- Thêm token_id vào đúng danh sách ---\n",
    "        if is_relation:\n",
    "            # Đây là một Relation\n",
    "            if concept2_ids:\n",
    "                # Nếu đã có concept2, tức là ta vừa kết thúc một triplet cũ\n",
    "                triplet = (\n",
    "                    ids_to_string(concept1_ids),\n",
    "                    ids_to_string(relation_ids),\n",
    "                    ids_to_string(concept2_ids)\n",
    "                )\n",
    "                if triplet not in triplets:\n",
    "                    triplets.append(triplet)\n",
    "\n",
    "                # Concept 2 cũ trở thành Concept 1 mới\n",
    "                concept1_ids = concept2_ids[:] # Phải copy\n",
    "                concept2_ids = []\n",
    "                relation_ids = []\n",
    "\n",
    "            relation_ids.append(token_id)\n",
    "        else:\n",
    "            # Đây là một Concept\n",
    "            if info['deprel'] == \"vmod\" and len(concept2_ids) == 0:\n",
    "                relation_ids.append(token_id)\n",
    "            elif relation_ids:\n",
    "                concept2_ids.append(token_id)\n",
    "            else:\n",
    "                # Nếu chưa có relation, token này thuộc về concept 1\n",
    "                concept1_ids.append(token_id)\n",
    "\n",
    "    # Xử lý triplet cuối cùng còn sót lại\n",
    "    if concept1_ids and relation_ids and concept2_ids:\n",
    "        triplet = (\n",
    "            ids_to_string(concept1_ids),\n",
    "            ids_to_string(relation_ids),\n",
    "            ids_to_string(concept2_ids)\n",
    "        )\n",
    "        if triplet not in triplets:\n",
    "            triplets.append(triplet)\n",
    "\n",
    "    return triplets\n",
    "\n",
    "# rows = extract_random_from_sqlite(process_cursor)\n",
    "rand_sentence = rows['content']\n",
    "# rand_sentence = \"\"\n",
    "print(rand_sentence)\n",
    "segmented_text = vncorenlp_client.word_segment(rand_sentence)\n",
    "annotation = phoNLP_model.annotate(text=segmented_text[0])\n",
    "df = parsing_result(annotation)\n",
    "print(df.to_string(index=False))\n",
    "result = process_sentence(df)\n",
    "for triplet in result:\n",
    "    print(triplet)"
   ],
   "id": "c0024dfa279607f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi phí vận hành khai thác công trình đường bộ được xác định theo quy định của pháp luật có liên quan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id       word pos head deprel\n",
      "  1    Chi_phí   N    6    sub\n",
      "  2   vận_hành   V    1   nmod\n",
      "  3  khai_thác   V    2   vmod\n",
      "  4 công_trình   N    2   vmod\n",
      "  5   đường_bộ   N    4   nmod\n",
      "  6       được   V    0   root\n",
      "  7   xác_định   V    6   vmod\n",
      "  8       theo   E    7    mnr\n",
      "  9   quy_định   V    8   vmod\n",
      " 10        của   E    9   nmod\n",
      " 11  pháp_luật   N   10    pob\n",
      " 12         có   V   11   nmod\n",
      " 13  liên_quan   V   12   vmod\n",
      "('Chi_phí', 'vận_hành khai_thác công_trình', 'đường_bộ được xác_định quy_định pháp_luật')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T14:15:15.503717Z",
     "start_time": "2025-10-24T14:15:15.252979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# Đã sửa logic nmod và vmod\n",
    "def process_sentence(df):\n",
    "    data_dict = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    if data_dict[1]['deprel'] == 'root':\n",
    "        return None\n",
    "\n",
    "    # === 1. Tiền xử lý ===\n",
    "    subjects_of_verbs = {}\n",
    "    for token_id, info in data_dict.items():\n",
    "        if info['deprel'] == 'sub':\n",
    "            head_id = info['head']\n",
    "            subjects_of_verbs.setdefault(head_id, []).append(token_id)\n",
    "\n",
    "    # === 2. Khởi tạo ===\n",
    "    triplets = []\n",
    "    concept1_groups = [[]]\n",
    "    concept2_groups = [[]]\n",
    "    relation_groups = [[]]\n",
    "\n",
    "    verb_deprel_tag = ['root', 'vmod', 'nmod', 'x', 'conj', 'prd', 'tpc', 'dep']\n",
    "    remove_POS_tag = [\"R\", \"CH\", \"E\", \"L\"]\n",
    "    coord_POS_tag = [\"C\"]\n",
    "    coord_words = {\"và\", \"hoặc\", \",\"}\n",
    "\n",
    "    def ids_to_string(id_list):\n",
    "        id_list = sorted(set(id_list))\n",
    "        return \" \".join(data_dict[tid]['word'] for tid in id_list if tid in data_dict)\n",
    "\n",
    "    def is_coord_word(info):\n",
    "        return (info[\"word\"].lower() in coord_words or\n",
    "                any(info['pos'].startswith(prefix) for prefix in coord_POS_tag))\n",
    "\n",
    "    token_ids = sorted(list(data_dict.keys()))\n",
    "    token_set = set(token_ids)\n",
    "\n",
    "    # === 3. Duyệt tokens ===\n",
    "    last_was_coord = False\n",
    "\n",
    "    for token_id in token_ids:\n",
    "        info = data_dict[token_id]\n",
    "\n",
    "        # Logic bỏ qua token\n",
    "        if any(info['pos'].startswith(prefix) for prefix in remove_POS_tag) and info['deprel'] != 'root':\n",
    "            continue\n",
    "\n",
    "        # Logic từ nối\n",
    "        if is_coord_word(info):\n",
    "            last_was_coord = True\n",
    "            continue\n",
    "\n",
    "        is_relation = False\n",
    "\n",
    "        # --- Logic 'vmod' (bắt buộc phải là 'V') ---\n",
    "        is_vmod_continuation = (\n",
    "            info['pos'].startswith(\"V\")\n",
    "            and info['deprel'] == \"vmod\"\n",
    "            and any(g for g in relation_groups if g)\n",
    "        )\n",
    "\n",
    "        # --- Logic 'relation' khác (bắt buộc phải là 'V') ---\n",
    "        prev_is_n = (token_id - 1 in token_set and data_dict[token_id - 1]['pos'].startswith(\"N\"))\n",
    "        next_is_n = (token_id + 1 in token_set and data_dict[token_id + 1]['pos'].startswith(\"N\"))\n",
    "\n",
    "        is_valid_relation_type = (\n",
    "            info['pos'].startswith(\"V\")\n",
    "            and info['deprel'] in verb_deprel_tag\n",
    "            and info['deprel'] not in (\"vmod\", \"root\")\n",
    "            and (info['deprel'] != \"nmod\" or (prev_is_n and next_is_n))\n",
    "        )\n",
    "\n",
    "        # --- Logic 'root' (Có thể là 'V' hoặc 'R') ---\n",
    "        is_valid_root = False\n",
    "        if info['deprel'] == \"root\":\n",
    "            is_valid_root = True\n",
    "\n",
    "        # Quyết định cuối cùng\n",
    "        if is_vmod_continuation or is_valid_relation_type or is_valid_root:\n",
    "            is_relation = True\n",
    "        target_groups = None\n",
    "\n",
    "        if is_relation:\n",
    "            # print(token_id) # Bỏ comment để debug\n",
    "            if any(g for g in concept2_groups if g):\n",
    "                # Hoàn thành triplet cũ\n",
    "                for c1g, rg, c2g in product(concept1_groups, relation_groups, concept2_groups):\n",
    "                    triplet = (ids_to_string(c1g), ids_to_string(rg), ids_to_string(c2g))\n",
    "                    if triplet not in triplets and c1g and rg and c2g:\n",
    "                        triplets.append(triplet)\n",
    "\n",
    "                concept1_groups = concept2_groups[:]\n",
    "                concept2_groups = [[]]\n",
    "                relation_groups = [[]]\n",
    "\n",
    "            target_groups = relation_groups\n",
    "        else:\n",
    "            # Nó là một Concept\n",
    "            if any(g for g in relation_groups if g):\n",
    "                target_groups = concept2_groups\n",
    "            else:\n",
    "                target_groups = concept1_groups\n",
    "\n",
    "        if last_was_coord:\n",
    "            # FORK: Tạo nhóm mới\n",
    "            if target_groups is not None:\n",
    "                target_groups.append([token_id])\n",
    "            last_was_coord = False\n",
    "        else:\n",
    "            # APPEND: Thêm vào nhóm cuối\n",
    "            if target_groups is not None:\n",
    "                if not target_groups or not target_groups[-1]:\n",
    "                     target_groups.append([token_id])\n",
    "                else:\n",
    "                     target_groups[-1].append(token_id)\n",
    "\n",
    "    # === 6. Kết thúc (Giữ nguyên) ===\n",
    "    for c1g, rg, c2g in product(concept1_groups, relation_groups, concept2_groups):\n",
    "        if c1g and rg and c2g:\n",
    "            triplet = (\n",
    "                ids_to_string(c1g),\n",
    "                ids_to_string(rg),\n",
    "                ids_to_string(c2g)\n",
    "            )\n",
    "            if triplet not in triplets:\n",
    "                triplets.append(triplet)\n",
    "    return triplets\n",
    "\n",
    "rows = extract_random_from_sqlite(process_cursor)\n",
    "rand_sentence = rows['content']\n",
    "# rand_sentence = \"\"\n",
    "print(rand_sentence)\n",
    "segmented_text = vncorenlp_client.word_segment(rand_sentence)\n",
    "annotation = phoNLP_model.annotate(text=segmented_text[0])\n",
    "df = parsing_result(annotation)\n",
    "print(df.to_string(index=False))\n",
    "result = process_sentence(df)\n",
    "if result:\n",
    "    for triplet in result:\n",
    "        print(triplet)\n",
    "else:\n",
    "    print(\"There was a problem with the sentence.\")"
   ],
   "id": "133cce579cc660db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cơ quan quản lý đường bộ có trách nhiệm thông báo kết quả khắc phục cho cá nhân đã kiến nghị trong phạm vi nhiệm vụ, quyền hạn của mình\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id        word pos head deprel\n",
      "  1     Cơ_quan   N    4    sub\n",
      "  2     quản_lý   V    1   nmod\n",
      "  3    đường_bộ   N    2    dob\n",
      "  4          có   V    0   root\n",
      "  5 trách_nhiệm   N    4    dob\n",
      "  6   thông_báo   V    5   nmod\n",
      "  7     kết_quả   N    6    dob\n",
      "  8   khắc_phục   V    7   nmod\n",
      "  9         cho   E    6    iob\n",
      " 10     cá_nhân   N    9    pob\n",
      " 11          đã   R   12    adv\n",
      " 12   kiến_nghị   V   10   nmod\n",
      " 13       trong   E   12    loc\n",
      " 14     phạm_vi   N   13    pob\n",
      " 15    nhiệm_vụ   N   14   nmod\n",
      " 16           ,  CH   15  punct\n",
      " 17   quyền_hạn   N   15   nmod\n",
      " 18         của   E   15   nmod\n",
      " 19        mình   P   18    pob\n",
      "('Cơ_quan', 'quản_lý', 'đường_bộ')\n",
      "('đường_bộ', 'có', 'trách_nhiệm')\n",
      "('trách_nhiệm', 'thông_báo', 'kết_quả khắc_phục cá_nhân kiến_nghị phạm_vi nhiệm_vụ quyền_hạn mình')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:07:02.540483Z",
     "start_time": "2025-10-24T10:07:02.535659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dict = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "# === 1. Tiền xử lý: Tìm chủ ngữ (sub) của tất cả các động từ ===\n",
    "subjects_of_verbs = {}\n",
    "for token_id, info in data_dict.items():\n",
    "    if info['deprel'] == 'sub':\n",
    "        head_id = info['head']\n",
    "        if head_id not in subjects_of_verbs:\n",
    "            subjects_of_verbs[head_id] = []\n",
    "        subjects_of_verbs[head_id].append(token_id)\n",
    "\n",
    "for subject_id in subjects_of_verbs:\n",
    "    print(subject_id)\n",
    "    print(subjects_of_verbs[subject_id])"
   ],
   "id": "64eb4650c61f3529",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[1]\n"
     ]
    }
   ],
   "execution_count": 120
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
